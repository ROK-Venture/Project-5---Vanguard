{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7aa32f7",
   "metadata": {},
   "source": [
    "# Data Cleaning & Analysis Template\n",
    "This notebook provides a structured approach to data cleaning and preprocessing for both tabular and geospatial datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "887e12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679e317",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c899767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 1. Load Data\n",
    "# ----------------------\n",
    "DEFAULT_DATA_DIR = r\"YOUR PATH TO ALL DATASETS\"\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"Load a dataset from the default directory and return it as a DataFrame.\"\"\"\n",
    "    file_path = os.path.join(DEFAULT_DATA_DIR, file_name)\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedce07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 2. Load Geospatial Data (Optional)\n",
    "# ----------------------\n",
    "def load_geodata(file_name):\n",
    "    \"\"\"Load a geospatial dataset from the default directory and return it as a GeoDataFrame.\"\"\"\n",
    "    file_path = os.path.join(DEFAULT_DATA_DIR, file_name)\n",
    "    return gpd.read_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 3. Example Usage\n",
    "# ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Define datasets\n",
    "    datasets = {\n",
    "        \"df_1\": \"dataset_1.csv\",\n",
    "        \"df_2\": \"dataset_2.csv\",\n",
    "        \"df_3\": \"dataset_3.csv\",\n",
    "        \"df_4\": \"dataset_4.csv\"\n",
    "    }\n",
    "    \n",
    "    # Load datasets dynamically\n",
    "    dfs = {df_name: load_data(file) for df_name, file in datasets.items()}\n",
    "    \n",
    "    print(\"Datasets loaded successfully.\")\n",
    "    \n",
    "    # Define geospatial datasets (Optional)\n",
    "    geodatasets = {\n",
    "        \"geo_df_1\": \"geodata_1.shp\",\n",
    "        \"geo_df_2\": \"geodata_2.geojson\"\n",
    "    }\n",
    "    \n",
    "    # Load geospatial datasets dynamically\n",
    "    geodfs = {df_name: load_geodata(file) for df_name, file in geodatasets.items()}\n",
    "    \n",
    "    print(\"Geospatial datasets loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab0941e",
   "metadata": {},
   "source": [
    "## 2. Basic Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(df):\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(df.describe(include='all'))\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nFirst 5 Rows:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a942a",
   "metadata": {},
   "source": [
    "## 3. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, method='ffill'):\n",
    "    if method == 'drop':\n",
    "        return df.dropna()\n",
    "    return df.fillna(method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc487c0",
   "metadata": {},
   "source": [
    "## 4. Handle Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b8216",
   "metadata": {},
   "source": [
    "## 5. Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_types(df, date_columns=None, category_columns=None):\n",
    "    if date_columns:\n",
    "        for col in date_columns:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    if category_columns:\n",
    "        for col in category_columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c4412",
   "metadata": {},
   "source": [
    "## 6. Detect Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, column):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(x=df[column])\n",
    "    plt.title(f'Outlier Detection - {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480a4b0",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86637f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    if 'column1' in df.columns and 'column2' in df.columns:\n",
    "        df['new_feature'] = df['column1'] / (df['column2'] + 1e-9)  # Avoid division by zero\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a4cdcf",
   "metadata": {},
   "source": [
    "## 8. Normalize/Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[columns] = scaler.fit_transform(df[columns])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf83489",
   "metadata": {},
   "source": [
    "## 9. Geospatial Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab72b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_geospatial_data(gdf):\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "    gdf = gdf.dropna(subset=['geometry'])\n",
    "    gdf['centroid'] = gdf.geometry.centroid\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcddfe09",
   "metadata": {},
   "source": [
    "## 10. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, file_path, is_geospatial=False):\n",
    "    if is_geospatial:\n",
    "        df.to_file(file_path, driver='GeoJSON')\n",
    "    else:\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e7798",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38819a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = \"your_dataset.csv\"\n",
    "    is_geospatial = False\n",
    "    \n",
    "    df = load_data(file_path, is_geospatial)\n",
    "    inspect_data(df)\n",
    "    df = handle_missing_values(df, method='ffill')\n",
    "    df = remove_duplicates(df)\n",
    "    df = convert_data_types(df, date_columns=['date_column'], category_columns=['category_column'])\n",
    "    df = create_features(df)\n",
    "    df = normalize_data(df, columns=['numeric_column'])\n",
    "    \n",
    "    if is_geospatial:\n",
    "        df = clean_geospatial_data(df)\n",
    "    \n",
    "    save_data(df, \"cleaned_data.csv\", is_geospatial)\n",
    "    print(\"Data cleaning complete and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
