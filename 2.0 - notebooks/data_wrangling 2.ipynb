{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7aa32f7",
   "metadata": {},
   "source": [
    "# Data Cleaning & Analysis Template\n",
    "This notebook provides a structured approach to data cleaning and preprocessing for both tabular and geospatial datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887e12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679e317",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c899767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 1. Load Data\n",
    "# ----------------------\n",
    "DEFAULT_DATA_DIR = r\"C:\\Users\\manoe.MC_ASUS\\Documents\\IRON HACK BOOTCAMP\\DAFT_Feb 2025\\projects\\Project 5\\1.0 - data\\1.1 - raw\"\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"Load a dataset from the default directory and return it as a DataFrame.\"\"\"\n",
    "    file_path = os.path.join(DEFAULT_DATA_DIR, file_name)\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5ed10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded and assigned to variables explicitly.\n"
     ]
    }
   ],
   "source": [
    "#2. Exemple Usage \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define datasets\n",
    "    datasets = {\n",
    "        \"df_final_demo\": \"df_final_demo.txt\",\n",
    "        \"df_final_experiment_clients\": \"df_final_experiment_clients.txt\",\n",
    "        \"df_final_web_data_pt_1\": \"df_final_web_data_pt_1.txt\",\n",
    "        \"df_final_web_data_pt_2\": \"df_final_web_data_pt_2.txt\"\n",
    "    }\n",
    "    \n",
    "    # Load datasets dynamically into separate variables and store them globally\n",
    "    globals()[\"df_final_demo\"] = load_data(datasets[\"df_final_demo\"])\n",
    "    globals()[\"df_final_experiment_clients\"] = load_data(datasets[\"df_final_experiment_clients\"])\n",
    "    globals()[\"df_final_web_data_pt_1\"] = load_data(datasets[\"df_final_web_data_pt_1\"])\n",
    "    globals()[\"df_final_web_data_pt_2\"] = load_data(datasets[\"df_final_web_data_pt_2\"])\n",
    "\n",
    "    print(\"Datasets loaded and assigned to variables explicitly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab0941e",
   "metadata": {},
   "source": [
    "## 2. Basic Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f59b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(df):\n",
    "    \"\"\"Prints basic inspection details of a DataFrame.\"\"\"\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(df.describe(include='all'))\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nFirst 5 Rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "def inspect_all_data(dfs):\n",
    "    \"\"\"Inspect all datasets dynamically.\"\"\"\n",
    "    for df_name, df in dfs.items():\n",
    "        print(f\"\\n### Inspecting {df_name} ###\")\n",
    "        inspect_data(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab4245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70609 entries, 0 to 70608\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   client_id         70609 non-null  int64  \n",
      " 1   clnt_tenure_yr    70595 non-null  float64\n",
      " 2   clnt_tenure_mnth  70595 non-null  float64\n",
      " 3   clnt_age          70594 non-null  float64\n",
      " 4   gendr             70595 non-null  object \n",
      " 5   num_accts         70595 non-null  float64\n",
      " 6   bal               70595 non-null  float64\n",
      " 7   calls_6_mnth      70595 non-null  float64\n",
      " 8   logons_6_mnth     70595 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 4.8+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "           client_id  clnt_tenure_yr  clnt_tenure_mnth      clnt_age  gendr  \\\n",
      "count   7.060900e+04    70595.000000      70595.000000  70594.000000  70595   \n",
      "unique           NaN             NaN               NaN           NaN      4   \n",
      "top              NaN             NaN               NaN           NaN      U   \n",
      "freq             NaN             NaN               NaN           NaN  24122   \n",
      "mean    5.004992e+06       12.052950        150.659367     46.442240    NaN   \n",
      "std     2.877278e+06        6.871819         82.089854     15.591273    NaN   \n",
      "min     1.690000e+02        2.000000         33.000000     13.500000    NaN   \n",
      "25%     2.519329e+06        6.000000         82.000000     32.500000    NaN   \n",
      "50%     5.016978e+06       11.000000        136.000000     47.000000    NaN   \n",
      "75%     7.483085e+06       16.000000        192.000000     59.000000    NaN   \n",
      "max     9.999839e+06       62.000000        749.000000     96.000000    NaN   \n",
      "\n",
      "           num_accts           bal  calls_6_mnth  logons_6_mnth  \n",
      "count   70595.000000  7.059500e+04  70595.000000   70595.000000  \n",
      "unique           NaN           NaN           NaN            NaN  \n",
      "top              NaN           NaN           NaN            NaN  \n",
      "freq             NaN           NaN           NaN            NaN  \n",
      "mean        2.255528  1.474452e+05      3.382478       5.566740  \n",
      "std         0.534997  3.015087e+05      2.236580       2.353286  \n",
      "min         1.000000  1.378942e+04      0.000000       1.000000  \n",
      "25%         2.000000  3.734683e+04      1.000000       4.000000  \n",
      "50%         2.000000  6.333290e+04      3.000000       5.000000  \n",
      "75%         2.000000  1.375449e+05      6.000000       7.000000  \n",
      "max         8.000000  1.632004e+07      7.000000       9.000000  \n",
      "\n",
      "Missing Values:\n",
      "client_id            0\n",
      "clnt_tenure_yr      14\n",
      "clnt_tenure_mnth    14\n",
      "clnt_age            15\n",
      "gendr               14\n",
      "num_accts           14\n",
      "bal                 14\n",
      "calls_6_mnth        14\n",
      "logons_6_mnth       14\n",
      "dtype: int64\n",
      "\n",
      "First 5 Rows:\n",
      "   client_id  clnt_tenure_yr  clnt_tenure_mnth  clnt_age gendr  num_accts  \\\n",
      "0     836976             6.0              73.0      60.5     U        2.0   \n",
      "1    2304905             7.0              94.0      58.0     U        2.0   \n",
      "2    1439522             5.0              64.0      32.0     U        2.0   \n",
      "3    1562045            16.0             198.0      49.0     M        2.0   \n",
      "4    5126305            12.0             145.0      33.0     F        2.0   \n",
      "\n",
      "         bal  calls_6_mnth  logons_6_mnth  \n",
      "0   45105.30           6.0            9.0  \n",
      "1  110860.30           6.0            9.0  \n",
      "2   52467.79           6.0            9.0  \n",
      "3   67454.65           3.0            6.0  \n",
      "4  103671.75           0.0            3.0  \n"
     ]
    }
   ],
   "source": [
    "inspect_data(df_final_demo)\n",
    "\n",
    "\n",
    "#missing values: ~15 in each column compared to client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e70084ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70609 entries, 0 to 70608\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   client_id  70609 non-null  int64 \n",
      " 1   Variation  50500 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "           client_id Variation\n",
      "count   7.060900e+04     50500\n",
      "unique           NaN         2\n",
      "top              NaN      Test\n",
      "freq             NaN     26968\n",
      "mean    5.004992e+06       NaN\n",
      "std     2.877278e+06       NaN\n",
      "min     1.690000e+02       NaN\n",
      "25%     2.519329e+06       NaN\n",
      "50%     5.016978e+06       NaN\n",
      "75%     7.483085e+06       NaN\n",
      "max     9.999839e+06       NaN\n",
      "\n",
      "Missing Values:\n",
      "client_id        0\n",
      "Variation    20109\n",
      "dtype: int64\n",
      "\n",
      "First 5 Rows:\n",
      "   client_id Variation\n",
      "0    9988021      Test\n",
      "1    8320017      Test\n",
      "2    4033851   Control\n",
      "3    1982004      Test\n",
      "4    9294070   Control\n"
     ]
    }
   ],
   "source": [
    "inspect_data(df_final_experiment_clients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd607c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 343141 entries, 0 to 343140\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   client_id     343141 non-null  int64 \n",
      " 1   visitor_id    343141 non-null  object\n",
      " 2   visit_id      343141 non-null  object\n",
      " 3   process_step  343141 non-null  object\n",
      " 4   date_time     343141 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 13.1+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "           client_id             visitor_id                     visit_id  \\\n",
      "count   3.431410e+05                 343141                       343141   \n",
      "unique           NaN                  62936                        75256   \n",
      "top              NaN  699275239_82397698587  712824876_8175482950_365042   \n",
      "freq             NaN                     66                           61   \n",
      "mean    4.996097e+06                    NaN                          NaN   \n",
      "std     2.875839e+06                    NaN                          NaN   \n",
      "min     1.690000e+02                    NaN                          NaN   \n",
      "25%     2.506067e+06                    NaN                          NaN   \n",
      "50%     5.007915e+06                    NaN                          NaN   \n",
      "75%     7.468519e+06                    NaN                          NaN   \n",
      "max     9.999839e+06                    NaN                          NaN   \n",
      "\n",
      "       process_step            date_time  \n",
      "count        343141               343141  \n",
      "unique            5               282666  \n",
      "top           start  2017-03-29 11:24:54  \n",
      "freq         108910                   14  \n",
      "mean            NaN                  NaN  \n",
      "std             NaN                  NaN  \n",
      "min             NaN                  NaN  \n",
      "25%             NaN                  NaN  \n",
      "50%             NaN                  NaN  \n",
      "75%             NaN                  NaN  \n",
      "max             NaN                  NaN  \n",
      "\n",
      "Missing Values:\n",
      "client_id       0\n",
      "visitor_id      0\n",
      "visit_id        0\n",
      "process_step    0\n",
      "date_time       0\n",
      "dtype: int64\n",
      "\n",
      "First 5 Rows:\n",
      "   client_id            visitor_id                      visit_id process_step  \\\n",
      "0    9988021  580560515_7732621733  781255054_21935453173_531117       step_3   \n",
      "1    9988021  580560515_7732621733  781255054_21935453173_531117       step_2   \n",
      "2    9988021  580560515_7732621733  781255054_21935453173_531117       step_3   \n",
      "3    9988021  580560515_7732621733  781255054_21935453173_531117       step_2   \n",
      "4    9988021  580560515_7732621733  781255054_21935453173_531117       step_3   \n",
      "\n",
      "             date_time  \n",
      "0  2017-04-17 15:27:07  \n",
      "1  2017-04-17 15:26:51  \n",
      "2  2017-04-17 15:19:22  \n",
      "3  2017-04-17 15:19:13  \n",
      "4  2017-04-17 15:18:04  \n"
     ]
    }
   ],
   "source": [
    "inspect_data(df_final_web_data_pt_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdb9a94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 412264 entries, 0 to 412263\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   client_id     412264 non-null  int64 \n",
      " 1   visitor_id    412264 non-null  object\n",
      " 2   visit_id      412264 non-null  object\n",
      " 3   process_step  412264 non-null  object\n",
      " 4   date_time     412264 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 15.7+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "           client_id            visitor_id                      visit_id  \\\n",
      "count   4.122640e+05                412264                        412264   \n",
      "unique           NaN                 71042                         82841   \n",
      "top              NaN  722943003_3441581446  875138661_34710212496_881092   \n",
      "freq             NaN                   104                           104   \n",
      "mean    5.028227e+06                   NaN                           NaN   \n",
      "std     2.881828e+06                   NaN                           NaN   \n",
      "min     3.360000e+02                   NaN                           NaN   \n",
      "25%     2.533952e+06                   NaN                           NaN   \n",
      "50%     5.056314e+06                   NaN                           NaN   \n",
      "75%     7.516792e+06                   NaN                           NaN   \n",
      "max     9.999875e+06                   NaN                           NaN   \n",
      "\n",
      "       process_step            date_time  \n",
      "count        412264               412264  \n",
      "unique            5               346697  \n",
      "top           start  2017-05-02 10:53:01  \n",
      "freq         135035                   24  \n",
      "mean            NaN                  NaN  \n",
      "std             NaN                  NaN  \n",
      "min             NaN                  NaN  \n",
      "25%             NaN                  NaN  \n",
      "50%             NaN                  NaN  \n",
      "75%             NaN                  NaN  \n",
      "max             NaN                  NaN  \n",
      "\n",
      "Missing Values:\n",
      "client_id       0\n",
      "visitor_id      0\n",
      "visit_id        0\n",
      "process_step    0\n",
      "date_time       0\n",
      "dtype: int64\n",
      "\n",
      "First 5 Rows:\n",
      "   client_id             visitor_id                      visit_id  \\\n",
      "0     763412  601952081_10457207388  397475557_40440946728_419634   \n",
      "1    6019349  442094451_91531546617  154620534_35331068705_522317   \n",
      "2    6019349  442094451_91531546617  154620534_35331068705_522317   \n",
      "3    6019349  442094451_91531546617  154620534_35331068705_522317   \n",
      "4    6019349  442094451_91531546617  154620534_35331068705_522317   \n",
      "\n",
      "  process_step            date_time  \n",
      "0      confirm  2017-06-06 08:56:00  \n",
      "1      confirm  2017-06-01 11:59:27  \n",
      "2       step_3  2017-06-01 11:58:48  \n",
      "3       step_2  2017-06-01 11:58:08  \n",
      "4       step_1  2017-06-01 11:57:58  \n"
     ]
    }
   ],
   "source": [
    "inspect_data(df_final_web_data_pt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a942a",
   "metadata": {},
   "source": [
    "## 3. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4e7ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, method='ffill'):\n",
    "    if method == 'drop':\n",
    "        return df.dropna()\n",
    "    return df.fillna(method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc487c0",
   "metadata": {},
   "source": [
    "## 4. Handle Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f18b87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b8216",
   "metadata": {},
   "source": [
    "## 5. Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1928467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_types(df, date_columns=None, category_columns=None):\n",
    "    if date_columns:\n",
    "        for col in date_columns:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    if category_columns:\n",
    "        for col in category_columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c4412",
   "metadata": {},
   "source": [
    "## 6. Detect Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a234cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, column):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(x=df[column])\n",
    "    plt.title(f'Outlier Detection - {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480a4b0",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86637f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    if 'column1' in df.columns and 'column2' in df.columns:\n",
    "        df['new_feature'] = df['column1'] / (df['column2'] + 1e-9)  # Avoid division by zero\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a4cdcf",
   "metadata": {},
   "source": [
    "## 8. Normalize/Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6878f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[columns] = scaler.fit_transform(df[columns])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcddfe09",
   "metadata": {},
   "source": [
    "## 9. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1953cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, file_path, is_geospatial=False):\n",
    "    if is_geospatial:\n",
    "        df.to_file(file_path, driver='GeoJSON')\n",
    "    else:\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e7798",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38819a68",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_data() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m is_geospatial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m load_data(file_path, is_geospatial)\n\u001b[0;32m      6\u001b[0m inspect_data(df)\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m handle_missing_values(df, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffill\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: load_data() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = \"your_dataset.csv\"\n",
    "    is_geospatial = False\n",
    "    \n",
    "    df = load_data(file_path, is_geospatial)\n",
    "    inspect_data(df)\n",
    "    df = handle_missing_values(df, method='ffill')\n",
    "    df = remove_duplicates(df)\n",
    "    df = convert_data_types(df, date_columns=['date_column'], category_columns=['category_column'])\n",
    "    df = create_features(df)\n",
    "    df = normalize_data(df, columns=['numeric_column'])\n",
    "    \n",
    "    if is_geospatial:\n",
    "        df = clean_geospatial_data(df)\n",
    "    \n",
    "    save_data(df, \"cleaned_data.csv\", is_geospatial)\n",
    "    print(\"Data cleaning complete and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
